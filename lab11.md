# 人工智能引发的伦理问题
> ### “强大的人工智能的崛起，要么是人类历史上最好的事，要么是最糟的。虽然是好是坏我们仍不确定。但应竭尽所能，确保其未来发展对我们有利。”---霍金

&emsp;&emsp;人工智能（英语：Artificial Intelligence, AI）亦称机器智能，是指由人制造出来的机器所表现出来的智能。通常人工智能是指通过普通电脑实现的智能。该词同时也指研究这样的智能系统是否能够实现，以及如何实现的科学领域。

&emsp;&emsp;伴随着新技术的快速发展，不可避免地出现了许多伦理道德问题。这已不单纯是哲学家需要思考的问题，而是需要全人类共同讨论的问题。如霍金先生所言，有些问题我们必须未雨绸缪，来确保人工智能的未来发展对我们有利。我们在此初步讨论几个问题。

## 自动驾驶引发的伦理问题
&emsp;&emsp;先来了解一下什么是**电车难题**：五个无辜的人被绑在电车轨道上。一辆失控的电车朝他们驶来，并且片刻后就要碾压到他们。幸运的是，你可以拉一个拉杆，让电车开到另一条轨道上。但是在那另一条轨道上也绑了一个人。你有两个选择：1. 不拉杆，五人死于你手下。2. 拉杆，一人死亡。你会怎么做呢？

&emsp;&emsp;类似的问题也出现在自动驾驶中：在美国布鲁金斯学会的一个无人驾驶汽车研讨会上，专家讨论了在危急时刻无人驾驶汽车应当怎样做。如果汽车为了保护自己的乘客而急刹车，但造成后方车辆追尾应如何？或当车辆为了躲避儿童进行急转，但撞到旁边其他人怎么办？实例是谷歌的撞车问题。一直致力于无人驾驶汽车研发的谷歌最近却陷入“撞车门”。安全行驶220多万公里后，其纪录于2月14日被终结。谷歌无人驾驶汽车在加州撞上一辆公交车，当时是为了躲避路边下水道入口处的沙袋，先停下、再启动，偏向了内侧车道。这是首次由无人驾驶汽车引发的事故。由于无人驾驶汽车过于遵守交通规则，在混乱、堵塞等路况出现时，很容易和不那么专心的人类司机撞车。谷歌的撞车事件也再次引发了对自动驾驶汽车的思考，即在实现了无人驾驶车的技术发展背后潜藏的一大串的伦理道德和法律问题。

&emsp;&emsp;自动驾驶时代正在到来，然而这些伦理道德问题却成为巨大的阻碍。法律的建立健全必不可少。

---

## 人工智能是否会威胁到人类
&emsp;&emsp;此前韩国围棋选手李世石大战谷歌的阿尔法狗并输掉一事引发了人们的热议。计算机的强大之处在于对数据的处理，若其拥有了智力，将是人脑所无法匹敌的。

&emsp;&emsp;若机器人拥有了人类般的智能，机器人是否也能拥有人权呢？他们是否甘心服务于人类呢？人类和机器人能否和平相处呢？类似的问题如果无法解决，人工智能就很有可能威胁到人类。这些问题必须在人工智能创立之初就解决。